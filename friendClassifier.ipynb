{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a71385d322e645d4bc037bfcda44d6ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cec5859bbab41c6b6e4b5c0ecc16182",
              "IPY_MODEL_41b6679a5e604faa85d27732b891ebf8",
              "IPY_MODEL_cdbe383666994f67b55277bdbf619673"
            ],
            "layout": "IPY_MODEL_d77cae753d6b425bb11dc21c08a90ec2"
          }
        },
        "4cec5859bbab41c6b6e4b5c0ecc16182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef2bdd7d652e4e5392776727a31e7038",
            "placeholder": "​",
            "style": "IPY_MODEL_edf8047264a349c58cfa1733ceb75011",
            "value": "100%"
          }
        },
        "41b6679a5e604faa85d27732b891ebf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17ecd5642bbe4917ba1f89f52b6301e3",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1f767d89ab94ac68f7cc936fa670f47",
            "value": 125
          }
        },
        "cdbe383666994f67b55277bdbf619673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d71f71cb9004d42b94830c9b8d1a64b",
            "placeholder": "​",
            "style": "IPY_MODEL_2d14d11835b74b7d95102529150126b0",
            "value": " 125/125 [05:55&lt;00:00,  3.11s/it]"
          }
        },
        "d77cae753d6b425bb11dc21c08a90ec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef2bdd7d652e4e5392776727a31e7038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edf8047264a349c58cfa1733ceb75011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17ecd5642bbe4917ba1f89f52b6301e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1f767d89ab94ac68f7cc936fa670f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d71f71cb9004d42b94830c9b8d1a64b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d14d11835b74b7d95102529150126b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsDbAtLjCane",
        "outputId": "53b3608f-bf3e-46fd-8988-bdc33eed754d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.24.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.26.2)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.7.4)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.8)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from pathlib import Path\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# Configure Selenium options for running in Colab\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "def search_and_download_duckduckgo(query, num=100):\n",
        "    # URL for DDG image search\n",
        "    url = f\"https://duckduckgo.com/?q={query}&t=h_&iax=images&ia=images\"\n",
        "\n",
        "    # Loads webpage at specified URL\n",
        "    driver.get(url)\n",
        "\n",
        "    # Wait for the page to load\n",
        "    time.sleep(5)\n",
        "\n",
        "    # Parse the page source\n",
        "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "    # Finds all images\n",
        "    image_elements = soup.find_all('img', limit=num)\n",
        "\n",
        "    # Setup path to a data folder\n",
        "    image_dir = \"data/animals\"\n",
        "\n",
        "    # Create new directory contingent on query\n",
        "    os.makedirs(os.path.join(image_dir, query), exist_ok=True)\n",
        "\n",
        "    page_num = 1\n",
        "    while len(image_elements) < num:\n",
        "        url = f\"https://duckduckgo.com/?q={query}&t=h_&iax=images&ia=images&page={page_num}\"\n",
        "        driver.get(url)\n",
        "        time.sleep(5)\n",
        "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "        new_image_elements = soup.find_all('img', limit=num - len(image_elements))\n",
        "        image_elements.extend(new_image_elements)\n",
        "        page_num += 1\n",
        "\n",
        "    print(f\"\\nFound {len(image_elements)} images of {query}\")\n",
        "\n",
        "    for i, img in enumerate(image_elements):\n",
        "      # Extract the image URL via attributes\n",
        "      image_url = img.get('src') or img.get('data-src')\n",
        "\n",
        "      # Handle relative URLs by converting them to absolute URLs\n",
        "      if image_url and not image_url.startswith('http'):\n",
        "        image_url = urljoin(url, image_url)\n",
        "\n",
        "      # Check if the URL is a direct link to the image\n",
        "      if image_url and image_url.startswith(\"http\"):\n",
        "        # Get the image URL\n",
        "        try:\n",
        "          response = requests.get(image_url)\n",
        "\n",
        "          # Renames image based on query & position\n",
        "          filename = f\"{query}_{i}.jpg\"\n",
        "\n",
        "          # Saves image to proper directory\n",
        "          with open(os.path.join(image_dir, query, filename), 'wb') as f:\n",
        "              f.write(response.content)\n",
        "          print(f\"Downloaded {filename}\")\n",
        "        except Exception as e:\n",
        "          print(f\"Error downloading {image_url}: {e}\")\n",
        "      else:\n",
        "        print(f\"Skipping non-direct URL: {image_url}\")"
      ],
      "metadata": {
        "id": "eKPT8Y931djS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_and_download_duckduckgo(\"cats\", 250)\n",
        "search_and_download_duckduckgo(\"dogs\", 250)\n",
        "search_and_download_duckduckgo(\"birds\", 250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwqwyCks-TRP",
        "outputId": "aa23013f-e9c3-4c27-f5fb-7b2d2ed238e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found 250 images of cats\n",
            "Downloaded cats_0.jpg\n",
            "Downloaded cats_1.jpg\n",
            "Downloaded cats_2.jpg\n",
            "Downloaded cats_3.jpg\n",
            "Downloaded cats_4.jpg\n",
            "Downloaded cats_5.jpg\n",
            "Downloaded cats_6.jpg\n",
            "Downloaded cats_7.jpg\n",
            "Downloaded cats_8.jpg\n",
            "Downloaded cats_9.jpg\n",
            "Downloaded cats_10.jpg\n",
            "Downloaded cats_11.jpg\n",
            "Downloaded cats_12.jpg\n",
            "Downloaded cats_13.jpg\n",
            "Downloaded cats_14.jpg\n",
            "Downloaded cats_15.jpg\n",
            "Downloaded cats_16.jpg\n",
            "Downloaded cats_17.jpg\n",
            "Downloaded cats_18.jpg\n",
            "Downloaded cats_19.jpg\n",
            "Downloaded cats_20.jpg\n",
            "Downloaded cats_21.jpg\n",
            "Downloaded cats_22.jpg\n",
            "Downloaded cats_23.jpg\n",
            "Downloaded cats_24.jpg\n",
            "Downloaded cats_25.jpg\n",
            "Downloaded cats_26.jpg\n",
            "Downloaded cats_27.jpg\n",
            "Downloaded cats_28.jpg\n",
            "Downloaded cats_29.jpg\n",
            "Downloaded cats_30.jpg\n",
            "Downloaded cats_31.jpg\n",
            "Downloaded cats_32.jpg\n",
            "Downloaded cats_33.jpg\n",
            "Downloaded cats_34.jpg\n",
            "Downloaded cats_35.jpg\n",
            "Downloaded cats_36.jpg\n",
            "Downloaded cats_37.jpg\n",
            "Downloaded cats_38.jpg\n",
            "Downloaded cats_39.jpg\n",
            "Downloaded cats_40.jpg\n",
            "Downloaded cats_41.jpg\n",
            "Downloaded cats_42.jpg\n",
            "Downloaded cats_43.jpg\n",
            "Downloaded cats_44.jpg\n",
            "Downloaded cats_45.jpg\n",
            "Downloaded cats_46.jpg\n",
            "Downloaded cats_47.jpg\n",
            "Downloaded cats_48.jpg\n",
            "Downloaded cats_49.jpg\n",
            "Downloaded cats_50.jpg\n",
            "Downloaded cats_51.jpg\n",
            "Downloaded cats_52.jpg\n",
            "Downloaded cats_53.jpg\n",
            "Downloaded cats_54.jpg\n",
            "Downloaded cats_55.jpg\n",
            "Downloaded cats_56.jpg\n",
            "Downloaded cats_57.jpg\n",
            "Downloaded cats_58.jpg\n",
            "Downloaded cats_59.jpg\n",
            "Downloaded cats_60.jpg\n",
            "Downloaded cats_61.jpg\n",
            "Downloaded cats_62.jpg\n",
            "Downloaded cats_63.jpg\n",
            "Downloaded cats_64.jpg\n",
            "Downloaded cats_65.jpg\n",
            "Downloaded cats_66.jpg\n",
            "Downloaded cats_67.jpg\n",
            "Downloaded cats_68.jpg\n",
            "Downloaded cats_69.jpg\n",
            "Downloaded cats_70.jpg\n",
            "Downloaded cats_71.jpg\n",
            "Downloaded cats_72.jpg\n",
            "Downloaded cats_73.jpg\n",
            "Downloaded cats_74.jpg\n",
            "Downloaded cats_75.jpg\n",
            "Downloaded cats_76.jpg\n",
            "Downloaded cats_77.jpg\n",
            "Downloaded cats_78.jpg\n",
            "Downloaded cats_79.jpg\n",
            "Downloaded cats_80.jpg\n",
            "Downloaded cats_81.jpg\n",
            "Downloaded cats_82.jpg\n",
            "Downloaded cats_83.jpg\n",
            "Downloaded cats_84.jpg\n",
            "Downloaded cats_85.jpg\n",
            "Downloaded cats_86.jpg\n",
            "Downloaded cats_87.jpg\n",
            "Downloaded cats_88.jpg\n",
            "Downloaded cats_89.jpg\n",
            "Downloaded cats_90.jpg\n",
            "Downloaded cats_91.jpg\n",
            "Downloaded cats_92.jpg\n",
            "Downloaded cats_93.jpg\n",
            "Downloaded cats_94.jpg\n",
            "Downloaded cats_95.jpg\n",
            "Downloaded cats_96.jpg\n",
            "Downloaded cats_97.jpg\n",
            "Downloaded cats_98.jpg\n",
            "Downloaded cats_99.jpg\n",
            "Downloaded cats_100.jpg\n",
            "Downloaded cats_101.jpg\n",
            "Downloaded cats_102.jpg\n",
            "Downloaded cats_103.jpg\n",
            "Downloaded cats_104.jpg\n",
            "Downloaded cats_105.jpg\n",
            "Downloaded cats_106.jpg\n",
            "Downloaded cats_107.jpg\n",
            "Downloaded cats_108.jpg\n",
            "Downloaded cats_109.jpg\n",
            "Downloaded cats_110.jpg\n",
            "Downloaded cats_111.jpg\n",
            "Downloaded cats_112.jpg\n",
            "Downloaded cats_113.jpg\n",
            "Downloaded cats_114.jpg\n",
            "Downloaded cats_115.jpg\n",
            "Downloaded cats_116.jpg\n",
            "Downloaded cats_117.jpg\n",
            "Downloaded cats_118.jpg\n",
            "Downloaded cats_119.jpg\n",
            "Downloaded cats_120.jpg\n",
            "Downloaded cats_121.jpg\n",
            "Downloaded cats_122.jpg\n",
            "Downloaded cats_123.jpg\n",
            "Downloaded cats_124.jpg\n",
            "Downloaded cats_125.jpg\n",
            "Downloaded cats_126.jpg\n",
            "Downloaded cats_127.jpg\n",
            "Downloaded cats_128.jpg\n",
            "Downloaded cats_129.jpg\n",
            "Downloaded cats_130.jpg\n",
            "Downloaded cats_131.jpg\n",
            "Downloaded cats_132.jpg\n",
            "Downloaded cats_133.jpg\n",
            "Downloaded cats_134.jpg\n",
            "Downloaded cats_135.jpg\n",
            "Downloaded cats_136.jpg\n",
            "Downloaded cats_137.jpg\n",
            "Downloaded cats_138.jpg\n",
            "Downloaded cats_139.jpg\n",
            "Downloaded cats_140.jpg\n",
            "Downloaded cats_141.jpg\n",
            "Downloaded cats_142.jpg\n",
            "Downloaded cats_143.jpg\n",
            "Downloaded cats_144.jpg\n",
            "Downloaded cats_145.jpg\n",
            "Downloaded cats_146.jpg\n",
            "Downloaded cats_147.jpg\n",
            "Downloaded cats_148.jpg\n",
            "Downloaded cats_149.jpg\n",
            "Downloaded cats_150.jpg\n",
            "Downloaded cats_151.jpg\n",
            "Downloaded cats_152.jpg\n",
            "Downloaded cats_153.jpg\n",
            "Downloaded cats_154.jpg\n",
            "Downloaded cats_155.jpg\n",
            "Downloaded cats_156.jpg\n",
            "Downloaded cats_157.jpg\n",
            "Downloaded cats_158.jpg\n",
            "Downloaded cats_159.jpg\n",
            "Downloaded cats_160.jpg\n",
            "Downloaded cats_161.jpg\n",
            "Downloaded cats_162.jpg\n",
            "Downloaded cats_163.jpg\n",
            "Downloaded cats_164.jpg\n",
            "Downloaded cats_165.jpg\n",
            "Downloaded cats_166.jpg\n",
            "Downloaded cats_167.jpg\n",
            "Downloaded cats_168.jpg\n",
            "Downloaded cats_169.jpg\n",
            "Downloaded cats_170.jpg\n",
            "Downloaded cats_171.jpg\n",
            "Downloaded cats_172.jpg\n",
            "Downloaded cats_173.jpg\n",
            "Downloaded cats_174.jpg\n",
            "Downloaded cats_175.jpg\n",
            "Downloaded cats_176.jpg\n",
            "Downloaded cats_177.jpg\n",
            "Downloaded cats_178.jpg\n",
            "Downloaded cats_179.jpg\n",
            "Downloaded cats_180.jpg\n",
            "Downloaded cats_181.jpg\n",
            "Downloaded cats_182.jpg\n",
            "Downloaded cats_183.jpg\n",
            "Downloaded cats_184.jpg\n",
            "Downloaded cats_185.jpg\n",
            "Downloaded cats_186.jpg\n",
            "Downloaded cats_187.jpg\n",
            "Downloaded cats_188.jpg\n",
            "Downloaded cats_189.jpg\n",
            "Downloaded cats_190.jpg\n",
            "Downloaded cats_191.jpg\n",
            "Downloaded cats_192.jpg\n",
            "Downloaded cats_193.jpg\n",
            "Downloaded cats_194.jpg\n",
            "Downloaded cats_195.jpg\n",
            "Downloaded cats_196.jpg\n",
            "Downloaded cats_197.jpg\n",
            "Downloaded cats_198.jpg\n",
            "Downloaded cats_199.jpg\n",
            "Downloaded cats_200.jpg\n",
            "Downloaded cats_201.jpg\n",
            "Downloaded cats_202.jpg\n",
            "Downloaded cats_203.jpg\n",
            "Downloaded cats_204.jpg\n",
            "Downloaded cats_205.jpg\n",
            "Downloaded cats_206.jpg\n",
            "Downloaded cats_207.jpg\n",
            "Downloaded cats_208.jpg\n",
            "Downloaded cats_209.jpg\n",
            "Downloaded cats_210.jpg\n",
            "Downloaded cats_211.jpg\n",
            "Downloaded cats_212.jpg\n",
            "Downloaded cats_213.jpg\n",
            "Downloaded cats_214.jpg\n",
            "Downloaded cats_215.jpg\n",
            "Downloaded cats_216.jpg\n",
            "Downloaded cats_217.jpg\n",
            "Downloaded cats_218.jpg\n",
            "Downloaded cats_219.jpg\n",
            "Downloaded cats_220.jpg\n",
            "Downloaded cats_221.jpg\n",
            "Downloaded cats_222.jpg\n",
            "Downloaded cats_223.jpg\n",
            "Downloaded cats_224.jpg\n",
            "Downloaded cats_225.jpg\n",
            "Downloaded cats_226.jpg\n",
            "Downloaded cats_227.jpg\n",
            "Downloaded cats_228.jpg\n",
            "Downloaded cats_229.jpg\n",
            "Downloaded cats_230.jpg\n",
            "Downloaded cats_231.jpg\n",
            "Downloaded cats_232.jpg\n",
            "Downloaded cats_233.jpg\n",
            "Downloaded cats_234.jpg\n",
            "Downloaded cats_235.jpg\n",
            "Downloaded cats_236.jpg\n",
            "Downloaded cats_237.jpg\n",
            "Downloaded cats_238.jpg\n",
            "Downloaded cats_239.jpg\n",
            "Downloaded cats_240.jpg\n",
            "Downloaded cats_241.jpg\n",
            "Downloaded cats_242.jpg\n",
            "Downloaded cats_243.jpg\n",
            "Downloaded cats_244.jpg\n",
            "Downloaded cats_245.jpg\n",
            "Downloaded cats_246.jpg\n",
            "Downloaded cats_247.jpg\n",
            "Downloaded cats_248.jpg\n",
            "Downloaded cats_249.jpg\n",
            "\n",
            "Found 250 images of dogs\n",
            "Downloaded dogs_0.jpg\n",
            "Downloaded dogs_1.jpg\n",
            "Downloaded dogs_2.jpg\n",
            "Downloaded dogs_3.jpg\n",
            "Downloaded dogs_4.jpg\n",
            "Downloaded dogs_5.jpg\n",
            "Downloaded dogs_6.jpg\n",
            "Downloaded dogs_7.jpg\n",
            "Downloaded dogs_8.jpg\n",
            "Downloaded dogs_9.jpg\n",
            "Downloaded dogs_10.jpg\n",
            "Downloaded dogs_11.jpg\n",
            "Downloaded dogs_12.jpg\n",
            "Downloaded dogs_13.jpg\n",
            "Downloaded dogs_14.jpg\n",
            "Downloaded dogs_15.jpg\n",
            "Downloaded dogs_16.jpg\n",
            "Downloaded dogs_17.jpg\n",
            "Downloaded dogs_18.jpg\n",
            "Downloaded dogs_19.jpg\n",
            "Downloaded dogs_20.jpg\n",
            "Downloaded dogs_21.jpg\n",
            "Downloaded dogs_22.jpg\n",
            "Downloaded dogs_23.jpg\n",
            "Downloaded dogs_24.jpg\n",
            "Downloaded dogs_25.jpg\n",
            "Downloaded dogs_26.jpg\n",
            "Downloaded dogs_27.jpg\n",
            "Downloaded dogs_28.jpg\n",
            "Downloaded dogs_29.jpg\n",
            "Downloaded dogs_30.jpg\n",
            "Downloaded dogs_31.jpg\n",
            "Downloaded dogs_32.jpg\n",
            "Downloaded dogs_33.jpg\n",
            "Downloaded dogs_34.jpg\n",
            "Downloaded dogs_35.jpg\n",
            "Downloaded dogs_36.jpg\n",
            "Downloaded dogs_37.jpg\n",
            "Downloaded dogs_38.jpg\n",
            "Downloaded dogs_39.jpg\n",
            "Downloaded dogs_40.jpg\n",
            "Downloaded dogs_41.jpg\n",
            "Downloaded dogs_42.jpg\n",
            "Downloaded dogs_43.jpg\n",
            "Downloaded dogs_44.jpg\n",
            "Downloaded dogs_45.jpg\n",
            "Downloaded dogs_46.jpg\n",
            "Downloaded dogs_47.jpg\n",
            "Downloaded dogs_48.jpg\n",
            "Downloaded dogs_49.jpg\n",
            "Downloaded dogs_50.jpg\n",
            "Downloaded dogs_51.jpg\n",
            "Downloaded dogs_52.jpg\n",
            "Downloaded dogs_53.jpg\n",
            "Downloaded dogs_54.jpg\n",
            "Downloaded dogs_55.jpg\n",
            "Downloaded dogs_56.jpg\n",
            "Downloaded dogs_57.jpg\n",
            "Downloaded dogs_58.jpg\n",
            "Downloaded dogs_59.jpg\n",
            "Downloaded dogs_60.jpg\n",
            "Downloaded dogs_61.jpg\n",
            "Downloaded dogs_62.jpg\n",
            "Downloaded dogs_63.jpg\n",
            "Downloaded dogs_64.jpg\n",
            "Downloaded dogs_65.jpg\n",
            "Downloaded dogs_66.jpg\n",
            "Downloaded dogs_67.jpg\n",
            "Downloaded dogs_68.jpg\n",
            "Downloaded dogs_69.jpg\n",
            "Downloaded dogs_70.jpg\n",
            "Downloaded dogs_71.jpg\n",
            "Downloaded dogs_72.jpg\n",
            "Downloaded dogs_73.jpg\n",
            "Downloaded dogs_74.jpg\n",
            "Downloaded dogs_75.jpg\n",
            "Downloaded dogs_76.jpg\n",
            "Downloaded dogs_77.jpg\n",
            "Downloaded dogs_78.jpg\n",
            "Downloaded dogs_79.jpg\n",
            "Downloaded dogs_80.jpg\n",
            "Downloaded dogs_81.jpg\n",
            "Downloaded dogs_82.jpg\n",
            "Downloaded dogs_83.jpg\n",
            "Downloaded dogs_84.jpg\n",
            "Downloaded dogs_85.jpg\n",
            "Downloaded dogs_86.jpg\n",
            "Downloaded dogs_87.jpg\n",
            "Downloaded dogs_88.jpg\n",
            "Downloaded dogs_89.jpg\n",
            "Downloaded dogs_90.jpg\n",
            "Downloaded dogs_91.jpg\n",
            "Downloaded dogs_92.jpg\n",
            "Downloaded dogs_93.jpg\n",
            "Downloaded dogs_94.jpg\n",
            "Downloaded dogs_95.jpg\n",
            "Downloaded dogs_96.jpg\n",
            "Downloaded dogs_97.jpg\n",
            "Downloaded dogs_98.jpg\n",
            "Downloaded dogs_99.jpg\n",
            "Downloaded dogs_100.jpg\n",
            "Downloaded dogs_101.jpg\n",
            "Downloaded dogs_102.jpg\n",
            "Downloaded dogs_103.jpg\n",
            "Downloaded dogs_104.jpg\n",
            "Downloaded dogs_105.jpg\n",
            "Downloaded dogs_106.jpg\n",
            "Downloaded dogs_107.jpg\n",
            "Downloaded dogs_108.jpg\n",
            "Downloaded dogs_109.jpg\n",
            "Downloaded dogs_110.jpg\n",
            "Downloaded dogs_111.jpg\n",
            "Downloaded dogs_112.jpg\n",
            "Downloaded dogs_113.jpg\n",
            "Downloaded dogs_114.jpg\n",
            "Downloaded dogs_115.jpg\n",
            "Downloaded dogs_116.jpg\n",
            "Downloaded dogs_117.jpg\n",
            "Downloaded dogs_118.jpg\n",
            "Downloaded dogs_119.jpg\n",
            "Downloaded dogs_120.jpg\n",
            "Downloaded dogs_121.jpg\n",
            "Downloaded dogs_122.jpg\n",
            "Downloaded dogs_123.jpg\n",
            "Downloaded dogs_124.jpg\n",
            "Downloaded dogs_125.jpg\n",
            "Downloaded dogs_126.jpg\n",
            "Downloaded dogs_127.jpg\n",
            "Downloaded dogs_128.jpg\n",
            "Downloaded dogs_129.jpg\n",
            "Downloaded dogs_130.jpg\n",
            "Downloaded dogs_131.jpg\n",
            "Downloaded dogs_132.jpg\n",
            "Downloaded dogs_133.jpg\n",
            "Downloaded dogs_134.jpg\n",
            "Downloaded dogs_135.jpg\n",
            "Downloaded dogs_136.jpg\n",
            "Downloaded dogs_137.jpg\n",
            "Downloaded dogs_138.jpg\n",
            "Downloaded dogs_139.jpg\n",
            "Downloaded dogs_140.jpg\n",
            "Downloaded dogs_141.jpg\n",
            "Downloaded dogs_142.jpg\n",
            "Downloaded dogs_143.jpg\n",
            "Downloaded dogs_144.jpg\n",
            "Downloaded dogs_145.jpg\n",
            "Downloaded dogs_146.jpg\n",
            "Downloaded dogs_147.jpg\n",
            "Downloaded dogs_148.jpg\n",
            "Downloaded dogs_149.jpg\n",
            "Downloaded dogs_150.jpg\n",
            "Downloaded dogs_151.jpg\n",
            "Downloaded dogs_152.jpg\n",
            "Downloaded dogs_153.jpg\n",
            "Downloaded dogs_154.jpg\n",
            "Downloaded dogs_155.jpg\n",
            "Downloaded dogs_156.jpg\n",
            "Downloaded dogs_157.jpg\n",
            "Downloaded dogs_158.jpg\n",
            "Downloaded dogs_159.jpg\n",
            "Downloaded dogs_160.jpg\n",
            "Downloaded dogs_161.jpg\n",
            "Downloaded dogs_162.jpg\n",
            "Downloaded dogs_163.jpg\n",
            "Downloaded dogs_164.jpg\n",
            "Downloaded dogs_165.jpg\n",
            "Downloaded dogs_166.jpg\n",
            "Downloaded dogs_167.jpg\n",
            "Downloaded dogs_168.jpg\n",
            "Downloaded dogs_169.jpg\n",
            "Downloaded dogs_170.jpg\n",
            "Downloaded dogs_171.jpg\n",
            "Downloaded dogs_172.jpg\n",
            "Downloaded dogs_173.jpg\n",
            "Downloaded dogs_174.jpg\n",
            "Downloaded dogs_175.jpg\n",
            "Downloaded dogs_176.jpg\n",
            "Downloaded dogs_177.jpg\n",
            "Downloaded dogs_178.jpg\n",
            "Downloaded dogs_179.jpg\n",
            "Downloaded dogs_180.jpg\n",
            "Downloaded dogs_181.jpg\n",
            "Downloaded dogs_182.jpg\n",
            "Downloaded dogs_183.jpg\n",
            "Downloaded dogs_184.jpg\n",
            "Downloaded dogs_185.jpg\n",
            "Downloaded dogs_186.jpg\n",
            "Downloaded dogs_187.jpg\n",
            "Downloaded dogs_188.jpg\n",
            "Downloaded dogs_189.jpg\n",
            "Downloaded dogs_190.jpg\n",
            "Downloaded dogs_191.jpg\n",
            "Downloaded dogs_192.jpg\n",
            "Downloaded dogs_193.jpg\n",
            "Downloaded dogs_194.jpg\n",
            "Downloaded dogs_195.jpg\n",
            "Downloaded dogs_196.jpg\n",
            "Downloaded dogs_197.jpg\n",
            "Downloaded dogs_198.jpg\n",
            "Downloaded dogs_199.jpg\n",
            "Downloaded dogs_200.jpg\n",
            "Downloaded dogs_201.jpg\n",
            "Downloaded dogs_202.jpg\n",
            "Downloaded dogs_203.jpg\n",
            "Downloaded dogs_204.jpg\n",
            "Downloaded dogs_205.jpg\n",
            "Downloaded dogs_206.jpg\n",
            "Downloaded dogs_207.jpg\n",
            "Downloaded dogs_208.jpg\n",
            "Downloaded dogs_209.jpg\n",
            "Downloaded dogs_210.jpg\n",
            "Downloaded dogs_211.jpg\n",
            "Downloaded dogs_212.jpg\n",
            "Downloaded dogs_213.jpg\n",
            "Downloaded dogs_214.jpg\n",
            "Downloaded dogs_215.jpg\n",
            "Downloaded dogs_216.jpg\n",
            "Downloaded dogs_217.jpg\n",
            "Downloaded dogs_218.jpg\n",
            "Downloaded dogs_219.jpg\n",
            "Downloaded dogs_220.jpg\n",
            "Downloaded dogs_221.jpg\n",
            "Downloaded dogs_222.jpg\n",
            "Downloaded dogs_223.jpg\n",
            "Downloaded dogs_224.jpg\n",
            "Downloaded dogs_225.jpg\n",
            "Downloaded dogs_226.jpg\n",
            "Downloaded dogs_227.jpg\n",
            "Downloaded dogs_228.jpg\n",
            "Downloaded dogs_229.jpg\n",
            "Downloaded dogs_230.jpg\n",
            "Downloaded dogs_231.jpg\n",
            "Downloaded dogs_232.jpg\n",
            "Downloaded dogs_233.jpg\n",
            "Downloaded dogs_234.jpg\n",
            "Downloaded dogs_235.jpg\n",
            "Downloaded dogs_236.jpg\n",
            "Downloaded dogs_237.jpg\n",
            "Downloaded dogs_238.jpg\n",
            "Downloaded dogs_239.jpg\n",
            "Downloaded dogs_240.jpg\n",
            "Downloaded dogs_241.jpg\n",
            "Downloaded dogs_242.jpg\n",
            "Downloaded dogs_243.jpg\n",
            "Downloaded dogs_244.jpg\n",
            "Downloaded dogs_245.jpg\n",
            "Downloaded dogs_246.jpg\n",
            "Downloaded dogs_247.jpg\n",
            "Downloaded dogs_248.jpg\n",
            "Downloaded dogs_249.jpg\n",
            "\n",
            "Found 250 images of birds\n",
            "Downloaded birds_0.jpg\n",
            "Downloaded birds_1.jpg\n",
            "Downloaded birds_2.jpg\n",
            "Downloaded birds_3.jpg\n",
            "Downloaded birds_4.jpg\n",
            "Downloaded birds_5.jpg\n",
            "Downloaded birds_6.jpg\n",
            "Downloaded birds_7.jpg\n",
            "Downloaded birds_8.jpg\n",
            "Downloaded birds_9.jpg\n",
            "Downloaded birds_10.jpg\n",
            "Downloaded birds_11.jpg\n",
            "Downloaded birds_12.jpg\n",
            "Downloaded birds_13.jpg\n",
            "Downloaded birds_14.jpg\n",
            "Downloaded birds_15.jpg\n",
            "Downloaded birds_16.jpg\n",
            "Downloaded birds_17.jpg\n",
            "Downloaded birds_18.jpg\n",
            "Downloaded birds_19.jpg\n",
            "Downloaded birds_20.jpg\n",
            "Downloaded birds_21.jpg\n",
            "Downloaded birds_22.jpg\n",
            "Downloaded birds_23.jpg\n",
            "Downloaded birds_24.jpg\n",
            "Downloaded birds_25.jpg\n",
            "Downloaded birds_26.jpg\n",
            "Downloaded birds_27.jpg\n",
            "Downloaded birds_28.jpg\n",
            "Downloaded birds_29.jpg\n",
            "Downloaded birds_30.jpg\n",
            "Downloaded birds_31.jpg\n",
            "Downloaded birds_32.jpg\n",
            "Downloaded birds_33.jpg\n",
            "Downloaded birds_34.jpg\n",
            "Downloaded birds_35.jpg\n",
            "Downloaded birds_36.jpg\n",
            "Downloaded birds_37.jpg\n",
            "Downloaded birds_38.jpg\n",
            "Downloaded birds_39.jpg\n",
            "Downloaded birds_40.jpg\n",
            "Downloaded birds_41.jpg\n",
            "Downloaded birds_42.jpg\n",
            "Downloaded birds_43.jpg\n",
            "Downloaded birds_44.jpg\n",
            "Downloaded birds_45.jpg\n",
            "Downloaded birds_46.jpg\n",
            "Downloaded birds_47.jpg\n",
            "Downloaded birds_48.jpg\n",
            "Downloaded birds_49.jpg\n",
            "Downloaded birds_50.jpg\n",
            "Downloaded birds_51.jpg\n",
            "Downloaded birds_52.jpg\n",
            "Downloaded birds_53.jpg\n",
            "Downloaded birds_54.jpg\n",
            "Downloaded birds_55.jpg\n",
            "Downloaded birds_56.jpg\n",
            "Downloaded birds_57.jpg\n",
            "Downloaded birds_58.jpg\n",
            "Downloaded birds_59.jpg\n",
            "Downloaded birds_60.jpg\n",
            "Downloaded birds_61.jpg\n",
            "Downloaded birds_62.jpg\n",
            "Downloaded birds_63.jpg\n",
            "Downloaded birds_64.jpg\n",
            "Downloaded birds_65.jpg\n",
            "Downloaded birds_66.jpg\n",
            "Downloaded birds_67.jpg\n",
            "Downloaded birds_68.jpg\n",
            "Downloaded birds_69.jpg\n",
            "Downloaded birds_70.jpg\n",
            "Downloaded birds_71.jpg\n",
            "Downloaded birds_72.jpg\n",
            "Downloaded birds_73.jpg\n",
            "Downloaded birds_74.jpg\n",
            "Downloaded birds_75.jpg\n",
            "Downloaded birds_76.jpg\n",
            "Downloaded birds_77.jpg\n",
            "Downloaded birds_78.jpg\n",
            "Downloaded birds_79.jpg\n",
            "Downloaded birds_80.jpg\n",
            "Downloaded birds_81.jpg\n",
            "Downloaded birds_82.jpg\n",
            "Downloaded birds_83.jpg\n",
            "Downloaded birds_84.jpg\n",
            "Downloaded birds_85.jpg\n",
            "Downloaded birds_86.jpg\n",
            "Downloaded birds_87.jpg\n",
            "Downloaded birds_88.jpg\n",
            "Downloaded birds_89.jpg\n",
            "Downloaded birds_90.jpg\n",
            "Downloaded birds_91.jpg\n",
            "Downloaded birds_92.jpg\n",
            "Downloaded birds_93.jpg\n",
            "Downloaded birds_94.jpg\n",
            "Downloaded birds_95.jpg\n",
            "Downloaded birds_96.jpg\n",
            "Downloaded birds_97.jpg\n",
            "Downloaded birds_98.jpg\n",
            "Downloaded birds_99.jpg\n",
            "Downloaded birds_100.jpg\n",
            "Downloaded birds_101.jpg\n",
            "Downloaded birds_102.jpg\n",
            "Downloaded birds_103.jpg\n",
            "Downloaded birds_104.jpg\n",
            "Downloaded birds_105.jpg\n",
            "Downloaded birds_106.jpg\n",
            "Downloaded birds_107.jpg\n",
            "Downloaded birds_108.jpg\n",
            "Downloaded birds_109.jpg\n",
            "Downloaded birds_110.jpg\n",
            "Downloaded birds_111.jpg\n",
            "Downloaded birds_112.jpg\n",
            "Downloaded birds_113.jpg\n",
            "Downloaded birds_114.jpg\n",
            "Downloaded birds_115.jpg\n",
            "Downloaded birds_116.jpg\n",
            "Downloaded birds_117.jpg\n",
            "Downloaded birds_118.jpg\n",
            "Downloaded birds_119.jpg\n",
            "Downloaded birds_120.jpg\n",
            "Downloaded birds_121.jpg\n",
            "Downloaded birds_122.jpg\n",
            "Downloaded birds_123.jpg\n",
            "Downloaded birds_124.jpg\n",
            "Downloaded birds_125.jpg\n",
            "Downloaded birds_126.jpg\n",
            "Downloaded birds_127.jpg\n",
            "Downloaded birds_128.jpg\n",
            "Downloaded birds_129.jpg\n",
            "Downloaded birds_130.jpg\n",
            "Downloaded birds_131.jpg\n",
            "Downloaded birds_132.jpg\n",
            "Downloaded birds_133.jpg\n",
            "Downloaded birds_134.jpg\n",
            "Downloaded birds_135.jpg\n",
            "Downloaded birds_136.jpg\n",
            "Downloaded birds_137.jpg\n",
            "Downloaded birds_138.jpg\n",
            "Downloaded birds_139.jpg\n",
            "Downloaded birds_140.jpg\n",
            "Downloaded birds_141.jpg\n",
            "Downloaded birds_142.jpg\n",
            "Downloaded birds_143.jpg\n",
            "Downloaded birds_144.jpg\n",
            "Downloaded birds_145.jpg\n",
            "Downloaded birds_146.jpg\n",
            "Downloaded birds_147.jpg\n",
            "Downloaded birds_148.jpg\n",
            "Downloaded birds_149.jpg\n",
            "Downloaded birds_150.jpg\n",
            "Downloaded birds_151.jpg\n",
            "Downloaded birds_152.jpg\n",
            "Downloaded birds_153.jpg\n",
            "Downloaded birds_154.jpg\n",
            "Downloaded birds_155.jpg\n",
            "Downloaded birds_156.jpg\n",
            "Downloaded birds_157.jpg\n",
            "Downloaded birds_158.jpg\n",
            "Downloaded birds_159.jpg\n",
            "Downloaded birds_160.jpg\n",
            "Downloaded birds_161.jpg\n",
            "Downloaded birds_162.jpg\n",
            "Downloaded birds_163.jpg\n",
            "Downloaded birds_164.jpg\n",
            "Downloaded birds_165.jpg\n",
            "Downloaded birds_166.jpg\n",
            "Downloaded birds_167.jpg\n",
            "Downloaded birds_168.jpg\n",
            "Downloaded birds_169.jpg\n",
            "Downloaded birds_170.jpg\n",
            "Downloaded birds_171.jpg\n",
            "Downloaded birds_172.jpg\n",
            "Downloaded birds_173.jpg\n",
            "Downloaded birds_174.jpg\n",
            "Downloaded birds_175.jpg\n",
            "Downloaded birds_176.jpg\n",
            "Downloaded birds_177.jpg\n",
            "Downloaded birds_178.jpg\n",
            "Downloaded birds_179.jpg\n",
            "Downloaded birds_180.jpg\n",
            "Downloaded birds_181.jpg\n",
            "Downloaded birds_182.jpg\n",
            "Downloaded birds_183.jpg\n",
            "Downloaded birds_184.jpg\n",
            "Downloaded birds_185.jpg\n",
            "Downloaded birds_186.jpg\n",
            "Downloaded birds_187.jpg\n",
            "Downloaded birds_188.jpg\n",
            "Downloaded birds_189.jpg\n",
            "Downloaded birds_190.jpg\n",
            "Downloaded birds_191.jpg\n",
            "Downloaded birds_192.jpg\n",
            "Downloaded birds_193.jpg\n",
            "Downloaded birds_194.jpg\n",
            "Downloaded birds_195.jpg\n",
            "Downloaded birds_196.jpg\n",
            "Downloaded birds_197.jpg\n",
            "Downloaded birds_198.jpg\n",
            "Downloaded birds_199.jpg\n",
            "Downloaded birds_200.jpg\n",
            "Downloaded birds_201.jpg\n",
            "Downloaded birds_202.jpg\n",
            "Downloaded birds_203.jpg\n",
            "Downloaded birds_204.jpg\n",
            "Downloaded birds_205.jpg\n",
            "Downloaded birds_206.jpg\n",
            "Downloaded birds_207.jpg\n",
            "Downloaded birds_208.jpg\n",
            "Downloaded birds_209.jpg\n",
            "Downloaded birds_210.jpg\n",
            "Downloaded birds_211.jpg\n",
            "Downloaded birds_212.jpg\n",
            "Downloaded birds_213.jpg\n",
            "Downloaded birds_214.jpg\n",
            "Downloaded birds_215.jpg\n",
            "Downloaded birds_216.jpg\n",
            "Downloaded birds_217.jpg\n",
            "Downloaded birds_218.jpg\n",
            "Downloaded birds_219.jpg\n",
            "Downloaded birds_220.jpg\n",
            "Downloaded birds_221.jpg\n",
            "Downloaded birds_222.jpg\n",
            "Downloaded birds_223.jpg\n",
            "Downloaded birds_224.jpg\n",
            "Downloaded birds_225.jpg\n",
            "Downloaded birds_226.jpg\n",
            "Downloaded birds_227.jpg\n",
            "Downloaded birds_228.jpg\n",
            "Downloaded birds_229.jpg\n",
            "Downloaded birds_230.jpg\n",
            "Downloaded birds_231.jpg\n",
            "Downloaded birds_232.jpg\n",
            "Downloaded birds_233.jpg\n",
            "Downloaded birds_234.jpg\n",
            "Downloaded birds_235.jpg\n",
            "Downloaded birds_236.jpg\n",
            "Downloaded birds_237.jpg\n",
            "Downloaded birds_238.jpg\n",
            "Downloaded birds_239.jpg\n",
            "Downloaded birds_240.jpg\n",
            "Downloaded birds_241.jpg\n",
            "Downloaded birds_242.jpg\n",
            "Downloaded birds_243.jpg\n",
            "Downloaded birds_244.jpg\n",
            "Downloaded birds_245.jpg\n",
            "Downloaded birds_246.jpg\n",
            "Downloaded birds_247.jpg\n",
            "Downloaded birds_248.jpg\n",
            "Downloaded birds_249.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set path of animals folder\n",
        "data_dir = Path(\"data/\")\n",
        "image_dir = data_dir / \"animals\"\n",
        "\n",
        "# Print path, # of sub-folders\n",
        "image_dir, len(list(image_dir.iterdir()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puqaWP5VfASF",
        "outputId": "78ec3e50-cd5b-4cfe-df4d-f3877e2ada6e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/animals'), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Ensure reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Augment data (assists CNN in learning minute details)\n",
        "data_transforms = transforms.Compose([\n",
        "    # Resize images to 64x64 for TinyVGG compatibility (basis of CNN)\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "\n",
        "    # Flip the images randomly on the horizontal\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "\n",
        "    transforms.RandomResizedCrop(64, scale=(.08, 1)),\n",
        "\n",
        "    # Turn the image into a torch.Tensor\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the images from subfolders\n",
        "imageDataset = datasets.ImageFolder(root=image_dir, transform=data_transforms)\n",
        "\n",
        "# 80/20 split between train & validation\n",
        "train_size = int(0.8 * len(imageDataset))\n",
        "validation_size = len(imageDataset) - train_size\n",
        "\n",
        "# Randomly split the data\n",
        "train_dataset, validation_dataset = random_split(imageDataset, [train_size, validation_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "wZmUjP7GeGcQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iJIDLXRioFbz",
        "outputId": "02aa5331-8781-4eb3-eb84-2c8d7fdbb255"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imageDataset[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtbSrlWRcjQC",
        "outputId": "46aaaaf3-4a9c-4461-8884-59c8da53c106"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify lengths of dataset\n",
        "len(train_dataset), len(validation_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfJLSBLarZK6",
        "outputId": "2fc5523a-bae0-4036-9c6b-e0f677285c80"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 150)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify classes of folders in list & dict form\n",
        "imageDataset.classes, imageDataset.class_to_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2PeVFOQsRSW",
        "outputId": "fb293834-07dd-4bc9-d7f1-272c7900cf5e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['birds', 'cats', 'dogs'], {'birds': 0, 'cats': 1, 'dogs': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a CNN\n",
        "class animalIdentifier(nn.Module):\n",
        "  \"\"\"\n",
        "  Model architecture to determine animal\n",
        "  Structure is as follows: For the two conv blocks: conv -> ReLU -> conv -> ReLU -> MaxPool\n",
        "  MaxPool is especially important as it decreases the spatial size of an image,\n",
        "  reducing the parameters & computation of the network. Essentially it allows for higher\n",
        "  higher level of pattern recognition in images (i.e. from edges to parts to objects & onward)\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    # Instantiate NN\n",
        "    super().__init__()\n",
        "\n",
        "    # First conv block\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "\n",
        "    # Second conv block\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "\n",
        "    # Third conv block\n",
        "    self.conv_block_3 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Dropout(p=0.5),  # 50% dropout\n",
        "        nn.Linear(in_features=hidden_units * 8 * 8, # Exact spatial dimension calculated\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.classifier(self.conv_block_3(self.conv_block_2(self.conv_block_1(x))))"
      ],
      "metadata": {
        "id": "1DJ8vAHoBio9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model with, in order: # of color channels, hidden_units, # of classes\n",
        "animalModel = animalIdentifier(input_shape=3,\n",
        "                               hidden_units=64,\n",
        "                               output_shape=len(imageDataset.classes)).to(device)\n",
        "\n",
        "animalModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEtDi4XsdOTt",
        "outputId": "1c9b933b-393d-4f47-c8a4-e8f1d00b4b0f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "animalIdentifier(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_3): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Dropout(p=0.5, inplace=False)\n",
              "    (2): Linear(in_features=4096, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve a single batch of data (batch of images & corresponding labels)\n",
        "image_batch, label_batch = next(iter(train_loader))\n",
        "image_batch.shape, label_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GtFaXZrugsJ",
        "outputId": "8e575684-9643-4d0e-d41f-aa4bef67aee4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3, 64, 64]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try a forward pass\n",
        "animalModel(image_batch.to(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgBhL_YHwIRP",
        "outputId": "c5f01869-c465-45da-c746-71d4a894276d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0030,  0.0080, -0.0064],\n",
              "        [-0.0074, -0.0038, -0.0150],\n",
              "        [-0.0296,  0.0148, -0.0243],\n",
              "        [-0.0006,  0.0199, -0.0140],\n",
              "        [-0.0251, -0.0015, -0.0044],\n",
              "        [ 0.0006,  0.0045, -0.0094],\n",
              "        [-0.0246,  0.0297, -0.0178],\n",
              "        [-0.0105, -0.0008, -0.0255],\n",
              "        [-0.0020,  0.0072, -0.0092],\n",
              "        [ 0.0025,  0.0504, -0.0254],\n",
              "        [-0.0412, -0.0056, -0.0283],\n",
              "        [-0.0136,  0.0135, -0.0259],\n",
              "        [-0.0050,  0.0137, -0.0130],\n",
              "        [-0.0010,  0.0281, -0.0204],\n",
              "        [-0.0308,  0.0106, -0.0154],\n",
              "        [-0.0118,  0.0142, -0.0116],\n",
              "        [-0.0151,  0.0074, -0.0137],\n",
              "        [-0.0070,  0.0142, -0.0284],\n",
              "        [-0.0246,  0.0291,  0.0116],\n",
              "        [-0.0134,  0.0362, -0.0200],\n",
              "        [-0.0253,  0.0003, -0.0210],\n",
              "        [-0.0215,  0.0272, -0.0185],\n",
              "        [-0.0164,  0.0290, -0.0158],\n",
              "        [-0.0068,  0.0070, -0.0001],\n",
              "        [ 0.0065,  0.0045, -0.0167],\n",
              "        [ 0.0090, -0.0032, -0.0087],\n",
              "        [ 0.0021,  0.0299, -0.0321],\n",
              "        [-0.0165,  0.0083,  0.0034],\n",
              "        [ 0.0100,  0.0221, -0.0140],\n",
              "        [-0.0235,  0.0295, -0.0092],\n",
              "        [-0.0135,  0.0217, -0.0134],\n",
              "        [-0.0028,  0.0242, -0.0014]], device='cuda:0',\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train step\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device=device):\n",
        "\n",
        "  # Put the model in train mode\n",
        "  model.train()\n",
        "\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  # Loop through batches\n",
        "  for batch in dataloader:\n",
        "    # Extract values from batch\n",
        "    images, labels = batch\n",
        "\n",
        "    # Send to device\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    predictions = model(images)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = loss_fn(predictions, labels) # Logits\n",
        "    train_loss += loss.item() # Cumulative loss\n",
        "\n",
        "    # Calculate accuracy\n",
        "    prediction_classes = torch.argmax(predictions, dim=1) # Predicted class (logits to classes)\n",
        "    train_acc += (prediction_classes == labels).sum().item() # Sum the number of correct predictions\n",
        "\n",
        "    # Set gradients to zero\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Step (learning rate)\n",
        "    optimizer.step()\n",
        "\n",
        "  # Average loss & accuracy per batch\n",
        "  train_loss = train_loss / len(dataloader)\n",
        "  train_acc = train_acc / len(dataloader.dataset) # Total correct / total samples\n",
        "\n",
        "  return train_loss, train_acc"
      ],
      "metadata": {
        "id": "LfiiBstBxF93"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation step\n",
        "def validation_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device=device):\n",
        "\n",
        "  # Put the model in eval mode\n",
        "  model.eval()\n",
        "\n",
        "  validation_loss, validation_acc = 0, 0\n",
        "\n",
        "  # Disables gradient computation, reduces memory usage & increases speed\n",
        "  with torch.inference_mode():\n",
        "\n",
        "    # Loop through batches\n",
        "    for batch in dataloader:\n",
        "      # Extract values from batch\n",
        "      images, labels = batch\n",
        "\n",
        "      # Send to device\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "      # Forward pass\n",
        "      predictions = model(images)\n",
        "\n",
        "      # Calculate the loss\n",
        "      loss = loss_fn(predictions, labels)\n",
        "      validation_loss += loss.item()\n",
        "\n",
        "      # Calculate accuracy\n",
        "      prediction_classes = torch.argmax(predictions, dim=1) # Predicted class (logits to classes)\n",
        "      validation_acc += (prediction_classes == labels).sum().item() # Sum the number of correct predictions\n",
        "\n",
        "  # Average loss & accuracy per batch\n",
        "  validation_loss = validation_loss / len(dataloader)\n",
        "  validation_acc = validation_acc / len(dataloader.dataset)\n",
        "\n",
        "  return validation_loss, validation_acc"
      ],
      "metadata": {
        "id": "N8khLkIS5gr_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine both train_step() & validation_step() into one function\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Takes in train & validation dataloaders, as well as everything needed to compute\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          validation_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int = 5,\n",
        "          device=device):\n",
        "\n",
        "  # Create dictionary to store results\n",
        "  results = {\"train_loss\": [],\n",
        "             \"train_acc\": [],\n",
        "             \"validation_loss\": [],\n",
        "             \"validation_acc\": []}\n",
        "\n",
        "  # Loop through train & validation steps for # of epochs\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model=model,\n",
        "                                       dataloader=train_dataloader,\n",
        "                                       loss_fn=loss_fn,\n",
        "                                       optimizer=optimizer,\n",
        "                                       device=device)\n",
        "\n",
        "    validation_loss, validation_acc = validation_step(model=model,\n",
        "                                    dataloader=validation_dataloader,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    device=device)\n",
        "\n",
        "    # Print data per epoch\n",
        "    print(f\"Epoch: {epoch} | Train loss: {train_loss:.4f} | Train acc: {train_acc:.4f} | Validation loss: {validation_loss:.4f} | Validation acc: {validation_acc:.4f}\")\n",
        "\n",
        "    # Update results dictionary\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"validation_loss\"].append(validation_loss)\n",
        "    results[\"validation_acc\"].append(validation_acc)\n",
        "\n",
        "  # Return filled results\n",
        "  return results"
      ],
      "metadata": {
        "id": "Eeql0YIZ7Z1T"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Time to train\n",
        "\n",
        "NUM_EPOCHS = 125\n",
        "\n",
        "# Recreate model from above\n",
        "animalModelV2 = animalIdentifier(input_shape=3,\n",
        "                               hidden_units=64,\n",
        "                               output_shape=len(imageDataset.classes)).to(device)\n",
        "\n",
        "# Configure loss function & optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=animalModelV2.parameters(),\n",
        "                            lr=0.001)\n",
        "\n",
        "# Timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Train\n",
        "results = train(model=animalModelV2,\n",
        "                train_dataloader=train_loader,\n",
        "                validation_dataloader=validation_loader,\n",
        "                optimizer=optimizer,\n",
        "                loss_fn=loss_fn,\n",
        "                epochs=NUM_EPOCHS,\n",
        "                device=device)\n",
        "\n",
        "# End the timer\n",
        "end_time = timer()\n",
        "print(f\"Total training time: {end_time - start_time:.3f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a71385d322e645d4bc037bfcda44d6ca",
            "4cec5859bbab41c6b6e4b5c0ecc16182",
            "41b6679a5e604faa85d27732b891ebf8",
            "cdbe383666994f67b55277bdbf619673",
            "d77cae753d6b425bb11dc21c08a90ec2",
            "ef2bdd7d652e4e5392776727a31e7038",
            "edf8047264a349c58cfa1733ceb75011",
            "17ecd5642bbe4917ba1f89f52b6301e3",
            "f1f767d89ab94ac68f7cc936fa670f47",
            "6d71f71cb9004d42b94830c9b8d1a64b",
            "2d14d11835b74b7d95102529150126b0"
          ]
        },
        "id": "bqZq4szb9G4I",
        "outputId": "9cfa8fe9-e50b-4c6f-8207-a7e1116b122f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a71385d322e645d4bc037bfcda44d6ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train loss: 1.0863 | Train acc: 0.3917 | Validation loss: 1.0395 | Validation acc: 0.3867\n",
            "Epoch: 1 | Train loss: 0.9468 | Train acc: 0.5317 | Validation loss: 0.9451 | Validation acc: 0.5200\n",
            "Epoch: 2 | Train loss: 0.9209 | Train acc: 0.5283 | Validation loss: 0.8658 | Validation acc: 0.5533\n",
            "Epoch: 3 | Train loss: 0.8753 | Train acc: 0.5667 | Validation loss: 0.9074 | Validation acc: 0.6133\n",
            "Epoch: 4 | Train loss: 0.7955 | Train acc: 0.6200 | Validation loss: 0.8958 | Validation acc: 0.5733\n",
            "Epoch: 5 | Train loss: 0.7972 | Train acc: 0.6033 | Validation loss: 0.8408 | Validation acc: 0.5267\n",
            "Epoch: 6 | Train loss: 0.8186 | Train acc: 0.5483 | Validation loss: 0.8399 | Validation acc: 0.5333\n",
            "Epoch: 7 | Train loss: 0.7792 | Train acc: 0.6200 | Validation loss: 0.7864 | Validation acc: 0.6200\n",
            "Epoch: 8 | Train loss: 0.7356 | Train acc: 0.6333 | Validation loss: 0.7694 | Validation acc: 0.6333\n",
            "Epoch: 9 | Train loss: 0.7183 | Train acc: 0.6450 | Validation loss: 0.7130 | Validation acc: 0.6200\n",
            "Epoch: 10 | Train loss: 0.7102 | Train acc: 0.6650 | Validation loss: 0.7647 | Validation acc: 0.6267\n",
            "Epoch: 11 | Train loss: 0.7438 | Train acc: 0.6433 | Validation loss: 0.6859 | Validation acc: 0.7333\n",
            "Epoch: 12 | Train loss: 0.7119 | Train acc: 0.6633 | Validation loss: 0.7434 | Validation acc: 0.6400\n",
            "Epoch: 13 | Train loss: 0.7024 | Train acc: 0.6750 | Validation loss: 0.7096 | Validation acc: 0.6400\n",
            "Epoch: 14 | Train loss: 0.6964 | Train acc: 0.6600 | Validation loss: 0.6601 | Validation acc: 0.7000\n",
            "Epoch: 15 | Train loss: 0.6699 | Train acc: 0.7000 | Validation loss: 0.6785 | Validation acc: 0.7333\n",
            "Epoch: 16 | Train loss: 0.6593 | Train acc: 0.7017 | Validation loss: 0.7022 | Validation acc: 0.6867\n",
            "Epoch: 17 | Train loss: 0.6800 | Train acc: 0.6783 | Validation loss: 0.6747 | Validation acc: 0.7200\n",
            "Epoch: 18 | Train loss: 0.6909 | Train acc: 0.6733 | Validation loss: 0.7186 | Validation acc: 0.6533\n",
            "Epoch: 19 | Train loss: 0.6867 | Train acc: 0.6767 | Validation loss: 0.7062 | Validation acc: 0.6533\n",
            "Epoch: 20 | Train loss: 0.6887 | Train acc: 0.6867 | Validation loss: 0.6710 | Validation acc: 0.6667\n",
            "Epoch: 21 | Train loss: 0.6364 | Train acc: 0.6950 | Validation loss: 0.7916 | Validation acc: 0.7133\n",
            "Epoch: 22 | Train loss: 0.6632 | Train acc: 0.7000 | Validation loss: 0.6853 | Validation acc: 0.6933\n",
            "Epoch: 23 | Train loss: 0.6659 | Train acc: 0.6817 | Validation loss: 0.7057 | Validation acc: 0.6733\n",
            "Epoch: 24 | Train loss: 0.6267 | Train acc: 0.7267 | Validation loss: 0.7894 | Validation acc: 0.6867\n",
            "Epoch: 25 | Train loss: 0.6151 | Train acc: 0.7300 | Validation loss: 0.7332 | Validation acc: 0.6333\n",
            "Epoch: 26 | Train loss: 0.5870 | Train acc: 0.7167 | Validation loss: 0.6050 | Validation acc: 0.7267\n",
            "Epoch: 27 | Train loss: 0.6052 | Train acc: 0.7333 | Validation loss: 0.6281 | Validation acc: 0.7133\n",
            "Epoch: 28 | Train loss: 0.5738 | Train acc: 0.7350 | Validation loss: 0.6601 | Validation acc: 0.6667\n",
            "Epoch: 29 | Train loss: 0.6597 | Train acc: 0.7283 | Validation loss: 0.6027 | Validation acc: 0.7133\n",
            "Epoch: 30 | Train loss: 0.6470 | Train acc: 0.7267 | Validation loss: 0.6255 | Validation acc: 0.6800\n",
            "Epoch: 31 | Train loss: 0.5893 | Train acc: 0.7200 | Validation loss: 0.6194 | Validation acc: 0.7467\n",
            "Epoch: 32 | Train loss: 0.5958 | Train acc: 0.7350 | Validation loss: 0.6092 | Validation acc: 0.6867\n",
            "Epoch: 33 | Train loss: 0.5352 | Train acc: 0.7600 | Validation loss: 0.5367 | Validation acc: 0.7600\n",
            "Epoch: 34 | Train loss: 0.5709 | Train acc: 0.7317 | Validation loss: 0.5950 | Validation acc: 0.7533\n",
            "Epoch: 35 | Train loss: 0.5545 | Train acc: 0.7383 | Validation loss: 0.5853 | Validation acc: 0.7000\n",
            "Epoch: 36 | Train loss: 0.5776 | Train acc: 0.7400 | Validation loss: 0.6005 | Validation acc: 0.7267\n",
            "Epoch: 37 | Train loss: 0.5838 | Train acc: 0.7250 | Validation loss: 0.6350 | Validation acc: 0.7000\n",
            "Epoch: 38 | Train loss: 0.5637 | Train acc: 0.7250 | Validation loss: 0.6059 | Validation acc: 0.7333\n",
            "Epoch: 39 | Train loss: 0.5755 | Train acc: 0.7450 | Validation loss: 0.7129 | Validation acc: 0.7000\n",
            "Epoch: 40 | Train loss: 0.5659 | Train acc: 0.7350 | Validation loss: 0.6469 | Validation acc: 0.6800\n",
            "Epoch: 41 | Train loss: 0.5876 | Train acc: 0.7450 | Validation loss: 0.5448 | Validation acc: 0.7800\n",
            "Epoch: 42 | Train loss: 0.5229 | Train acc: 0.7800 | Validation loss: 0.5088 | Validation acc: 0.7800\n",
            "Epoch: 43 | Train loss: 0.5060 | Train acc: 0.7733 | Validation loss: 0.5876 | Validation acc: 0.7267\n",
            "Epoch: 44 | Train loss: 0.4985 | Train acc: 0.7900 | Validation loss: 0.4765 | Validation acc: 0.7867\n",
            "Epoch: 45 | Train loss: 0.4965 | Train acc: 0.7600 | Validation loss: 0.5436 | Validation acc: 0.7733\n",
            "Epoch: 46 | Train loss: 0.5102 | Train acc: 0.7917 | Validation loss: 0.5996 | Validation acc: 0.7333\n",
            "Epoch: 47 | Train loss: 0.5437 | Train acc: 0.7433 | Validation loss: 0.5298 | Validation acc: 0.7533\n",
            "Epoch: 48 | Train loss: 0.4869 | Train acc: 0.7883 | Validation loss: 0.5314 | Validation acc: 0.7733\n",
            "Epoch: 49 | Train loss: 0.4983 | Train acc: 0.7850 | Validation loss: 0.5465 | Validation acc: 0.7400\n",
            "Epoch: 50 | Train loss: 0.4746 | Train acc: 0.8033 | Validation loss: 0.4661 | Validation acc: 0.8067\n",
            "Epoch: 51 | Train loss: 0.5079 | Train acc: 0.7617 | Validation loss: 0.5528 | Validation acc: 0.7400\n",
            "Epoch: 52 | Train loss: 0.4453 | Train acc: 0.8067 | Validation loss: 0.5385 | Validation acc: 0.7667\n",
            "Epoch: 53 | Train loss: 0.4493 | Train acc: 0.8083 | Validation loss: 0.4813 | Validation acc: 0.7933\n",
            "Epoch: 54 | Train loss: 0.4837 | Train acc: 0.8000 | Validation loss: 0.5361 | Validation acc: 0.7600\n",
            "Epoch: 55 | Train loss: 0.4862 | Train acc: 0.7800 | Validation loss: 0.4857 | Validation acc: 0.8000\n",
            "Epoch: 56 | Train loss: 0.4780 | Train acc: 0.7733 | Validation loss: 0.5169 | Validation acc: 0.7533\n",
            "Epoch: 57 | Train loss: 0.4719 | Train acc: 0.7917 | Validation loss: 0.5694 | Validation acc: 0.7667\n",
            "Epoch: 58 | Train loss: 0.4182 | Train acc: 0.8117 | Validation loss: 0.6122 | Validation acc: 0.7467\n",
            "Epoch: 59 | Train loss: 0.4059 | Train acc: 0.8267 | Validation loss: 0.5586 | Validation acc: 0.7733\n",
            "Epoch: 60 | Train loss: 0.3794 | Train acc: 0.8450 | Validation loss: 0.4911 | Validation acc: 0.7800\n",
            "Epoch: 61 | Train loss: 0.3874 | Train acc: 0.8583 | Validation loss: 0.5745 | Validation acc: 0.7467\n",
            "Epoch: 62 | Train loss: 0.4045 | Train acc: 0.8217 | Validation loss: 0.6604 | Validation acc: 0.6733\n",
            "Epoch: 63 | Train loss: 0.3911 | Train acc: 0.8283 | Validation loss: 0.5951 | Validation acc: 0.7733\n",
            "Epoch: 64 | Train loss: 0.4052 | Train acc: 0.8283 | Validation loss: 0.4638 | Validation acc: 0.8467\n",
            "Epoch: 65 | Train loss: 0.3715 | Train acc: 0.8583 | Validation loss: 0.5271 | Validation acc: 0.7867\n",
            "Epoch: 66 | Train loss: 0.3748 | Train acc: 0.8500 | Validation loss: 0.5328 | Validation acc: 0.8200\n",
            "Epoch: 67 | Train loss: 0.3969 | Train acc: 0.8333 | Validation loss: 0.5913 | Validation acc: 0.7333\n",
            "Epoch: 68 | Train loss: 0.3714 | Train acc: 0.8333 | Validation loss: 0.5331 | Validation acc: 0.8000\n",
            "Epoch: 69 | Train loss: 0.4062 | Train acc: 0.8200 | Validation loss: 0.4621 | Validation acc: 0.8133\n",
            "Epoch: 70 | Train loss: 0.4020 | Train acc: 0.8250 | Validation loss: 0.5540 | Validation acc: 0.7867\n",
            "Epoch: 71 | Train loss: 0.4103 | Train acc: 0.8400 | Validation loss: 0.5099 | Validation acc: 0.8200\n",
            "Epoch: 72 | Train loss: 0.3570 | Train acc: 0.8350 | Validation loss: 0.4119 | Validation acc: 0.8533\n",
            "Epoch: 73 | Train loss: 0.3495 | Train acc: 0.8533 | Validation loss: 0.4416 | Validation acc: 0.8133\n",
            "Epoch: 74 | Train loss: 0.3025 | Train acc: 0.8683 | Validation loss: 0.5510 | Validation acc: 0.7867\n",
            "Epoch: 75 | Train loss: 0.2951 | Train acc: 0.8750 | Validation loss: 0.5531 | Validation acc: 0.8067\n",
            "Epoch: 76 | Train loss: 0.3540 | Train acc: 0.8767 | Validation loss: 0.6320 | Validation acc: 0.7533\n",
            "Epoch: 77 | Train loss: 0.3573 | Train acc: 0.8633 | Validation loss: 0.4215 | Validation acc: 0.8000\n",
            "Epoch: 78 | Train loss: 0.3579 | Train acc: 0.8500 | Validation loss: 0.4216 | Validation acc: 0.8333\n",
            "Epoch: 79 | Train loss: 0.3201 | Train acc: 0.8783 | Validation loss: 0.4343 | Validation acc: 0.8267\n",
            "Epoch: 80 | Train loss: 0.3222 | Train acc: 0.8617 | Validation loss: 0.5113 | Validation acc: 0.8200\n",
            "Epoch: 81 | Train loss: 0.2667 | Train acc: 0.8900 | Validation loss: 0.4581 | Validation acc: 0.8200\n",
            "Epoch: 82 | Train loss: 0.3043 | Train acc: 0.8717 | Validation loss: 0.5405 | Validation acc: 0.8267\n",
            "Epoch: 83 | Train loss: 0.3025 | Train acc: 0.8750 | Validation loss: 0.5095 | Validation acc: 0.8067\n",
            "Epoch: 84 | Train loss: 0.2816 | Train acc: 0.8767 | Validation loss: 0.5967 | Validation acc: 0.8067\n",
            "Epoch: 85 | Train loss: 0.2620 | Train acc: 0.8867 | Validation loss: 0.5488 | Validation acc: 0.7867\n",
            "Epoch: 86 | Train loss: 0.2999 | Train acc: 0.8900 | Validation loss: 0.5437 | Validation acc: 0.8267\n",
            "Epoch: 87 | Train loss: 0.2910 | Train acc: 0.8750 | Validation loss: 0.4469 | Validation acc: 0.8400\n",
            "Epoch: 88 | Train loss: 0.2794 | Train acc: 0.8900 | Validation loss: 0.5333 | Validation acc: 0.7933\n",
            "Epoch: 89 | Train loss: 0.2520 | Train acc: 0.9033 | Validation loss: 0.6098 | Validation acc: 0.8000\n",
            "Epoch: 90 | Train loss: 0.3533 | Train acc: 0.8700 | Validation loss: 0.4312 | Validation acc: 0.8200\n",
            "Epoch: 91 | Train loss: 0.3083 | Train acc: 0.8867 | Validation loss: 0.5178 | Validation acc: 0.7667\n",
            "Epoch: 92 | Train loss: 0.3104 | Train acc: 0.8800 | Validation loss: 0.5726 | Validation acc: 0.8133\n",
            "Epoch: 93 | Train loss: 0.2821 | Train acc: 0.8900 | Validation loss: 0.4138 | Validation acc: 0.8467\n",
            "Epoch: 94 | Train loss: 0.3029 | Train acc: 0.8650 | Validation loss: 0.5939 | Validation acc: 0.8000\n",
            "Epoch: 95 | Train loss: 0.3973 | Train acc: 0.8267 | Validation loss: 0.4824 | Validation acc: 0.8133\n",
            "Epoch: 96 | Train loss: 0.3087 | Train acc: 0.8783 | Validation loss: 0.3864 | Validation acc: 0.8600\n",
            "Epoch: 97 | Train loss: 0.2717 | Train acc: 0.8833 | Validation loss: 0.6062 | Validation acc: 0.8200\n",
            "Epoch: 98 | Train loss: 0.2278 | Train acc: 0.9117 | Validation loss: 0.5223 | Validation acc: 0.8133\n",
            "Epoch: 99 | Train loss: 0.2546 | Train acc: 0.8867 | Validation loss: 0.3972 | Validation acc: 0.8733\n",
            "Epoch: 100 | Train loss: 0.3222 | Train acc: 0.8783 | Validation loss: 0.5277 | Validation acc: 0.8267\n",
            "Epoch: 101 | Train loss: 0.2656 | Train acc: 0.8900 | Validation loss: 0.5798 | Validation acc: 0.7733\n",
            "Epoch: 102 | Train loss: 0.2660 | Train acc: 0.8850 | Validation loss: 0.4451 | Validation acc: 0.8200\n",
            "Epoch: 103 | Train loss: 0.2633 | Train acc: 0.9067 | Validation loss: 0.4161 | Validation acc: 0.8667\n",
            "Epoch: 104 | Train loss: 0.2989 | Train acc: 0.8867 | Validation loss: 0.4810 | Validation acc: 0.8133\n",
            "Epoch: 105 | Train loss: 0.3106 | Train acc: 0.8867 | Validation loss: 0.4050 | Validation acc: 0.8733\n",
            "Epoch: 106 | Train loss: 0.3430 | Train acc: 0.8667 | Validation loss: 0.4843 | Validation acc: 0.8333\n",
            "Epoch: 107 | Train loss: 0.2552 | Train acc: 0.8867 | Validation loss: 0.4378 | Validation acc: 0.8000\n",
            "Epoch: 108 | Train loss: 0.2652 | Train acc: 0.9083 | Validation loss: 0.3537 | Validation acc: 0.8733\n",
            "Epoch: 109 | Train loss: 0.2492 | Train acc: 0.9000 | Validation loss: 0.4289 | Validation acc: 0.8400\n",
            "Epoch: 110 | Train loss: 0.2096 | Train acc: 0.9250 | Validation loss: 0.3878 | Validation acc: 0.8467\n",
            "Epoch: 111 | Train loss: 0.1969 | Train acc: 0.9117 | Validation loss: 0.4607 | Validation acc: 0.8600\n",
            "Epoch: 112 | Train loss: 0.2553 | Train acc: 0.8983 | Validation loss: 0.4488 | Validation acc: 0.8533\n",
            "Epoch: 113 | Train loss: 0.2175 | Train acc: 0.9117 | Validation loss: 0.4663 | Validation acc: 0.8667\n",
            "Epoch: 114 | Train loss: 0.2119 | Train acc: 0.9200 | Validation loss: 0.3986 | Validation acc: 0.8800\n",
            "Epoch: 115 | Train loss: 0.2076 | Train acc: 0.9083 | Validation loss: 0.5477 | Validation acc: 0.8133\n",
            "Epoch: 116 | Train loss: 0.2324 | Train acc: 0.9033 | Validation loss: 0.3699 | Validation acc: 0.8600\n",
            "Epoch: 117 | Train loss: 0.1396 | Train acc: 0.9417 | Validation loss: 0.5239 | Validation acc: 0.8333\n",
            "Epoch: 118 | Train loss: 0.1527 | Train acc: 0.9350 | Validation loss: 0.4557 | Validation acc: 0.8867\n",
            "Epoch: 119 | Train loss: 0.1732 | Train acc: 0.9233 | Validation loss: 0.5087 | Validation acc: 0.8600\n",
            "Epoch: 120 | Train loss: 0.1853 | Train acc: 0.9283 | Validation loss: 0.5776 | Validation acc: 0.8000\n",
            "Epoch: 121 | Train loss: 0.2670 | Train acc: 0.8917 | Validation loss: 0.5858 | Validation acc: 0.8467\n",
            "Epoch: 122 | Train loss: 0.2601 | Train acc: 0.9050 | Validation loss: 0.5110 | Validation acc: 0.8267\n",
            "Epoch: 123 | Train loss: 0.1884 | Train acc: 0.9283 | Validation loss: 0.6125 | Validation acc: 0.8067\n",
            "Epoch: 124 | Train loss: 0.2068 | Train acc: 0.9067 | Validation loss: 0.5474 | Validation acc: 0.8067\n",
            "Total training time: 355.821 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model directory\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True,\n",
        "                 exist_ok=True)\n",
        "\n",
        "# Create model name & save path\n",
        "MODEL_NAME = \"animalClassifier.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# Save model's weights to created path\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=animalModelV2.state_dict(),\n",
        "           f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edm8cFA--bgF",
        "outputId": "6034263f-a6b5-4f4c-aba8-378dea177979"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to: models/animalClassifier.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "peopleClassifier = animalIdentifier(input_shape=3,\n",
        "                               hidden_units=64,\n",
        "                               output_shape=len(imageDataset.classes))\n",
        "\n",
        "# Load pre-trained weights\n",
        "modelWeightsPath = MODEL_SAVE_PATH\n",
        "stateDict = torch.load(modelWeightsPath)\n",
        "peopleClassifier.load_state_dict(stateDict)\n",
        "\n",
        "# Move to device\n",
        "peopleClassifier.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziaYzPJBPqtb",
        "outputId": "d90e0da8-45bb-4b07-a193-d88cf5934d5c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-2c4f0e55305b>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  stateDict = torch.load(modelWeightsPath)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "animalIdentifier(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_3): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Dropout(p=0.5, inplace=False)\n",
              "    (2): Linear(in_features=4096, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "print(drive.mount('/content/drive'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp2coSH-6Zk-",
        "outputId": "23824c30-1314-4fb3-9aad-3cbd0f9877ad"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set path of animals folder\n",
        "drive_dir = Path(\"drive/\")\n",
        "image_dir = drive_dir / \"MyDrive/Hateocracy\"\n",
        "\n",
        "# Print path, # of sub-folders\n",
        "image_dir, len(list(image_dir.iterdir()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYo5uek2yHx7",
        "outputId": "b535b17d-2e57-447e-c938-01af1cbdfc48"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('drive/MyDrive/Hateocracy'), 10)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Augment data (assists CNN in learning minute details)\n",
        "new_data_transforms = transforms.Compose([\n",
        "    # Resize images to 64x64 for TinyVGG compatibility (basis of CNN)\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "\n",
        "    # Flip the images randomly on the horizontal\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "\n",
        "    # Flip the images randomly on the vertical\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "\n",
        "    transforms.RandomRotation(15),\n",
        "\n",
        "    transforms.RandomResizedCrop(64, scale=(.08, 1)),\n",
        "\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),\n",
        "\n",
        "    # Turn the image into a torch.Tensor\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the images from subfolders\n",
        "newImageDataset = datasets.ImageFolder(root=image_dir, transform=new_data_transforms)\n",
        "\n",
        "# Create DataLoaders\n",
        "new_train_loader = DataLoader(newImageDataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "xa_OfsbQ3jND"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "k_folds = 5\n",
        "\n",
        "# Prepare cross-validation\n",
        "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(newImageDataset)):\n",
        "    print(f'Fold {fold+1}/{k_folds}')\n",
        "\n",
        "    # Prepare data loaders for this fold\n",
        "    train_subset = Subset(newImageDataset, train_idx)\n",
        "    new_train_loader = DataLoader(train_subset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHEjTOjs0kwa",
        "outputId": "35d114d7-bfe3-4be2-bf10-c8cb0b75b42a"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5\n",
            "Fold 2/5\n",
            "Fold 3/5\n",
            "Fold 4/5\n",
            "Fold 5/5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify lengths of dataset\n",
        "len(newImageDataset), len(newImageDataset.classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX0Sdi0yE4vT",
        "outputId": "25e7f643-195d-4ac1-e870-0460852872d5"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify final layer of model to match the number of classes in new dataset\n",
        "num_classes = len(newImageDataset.classes)\n",
        "\n",
        "# Load the pretrained model\n",
        "peopleClassifier.classifier = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Dropout(p=0.7),\n",
        "    nn.Linear(in_features=64 * 8 * 8, out_features=num_classes)\n",
        ")\n",
        "\n",
        "# Move to device\n",
        "peopleClassifier.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXNyTtisFTp-",
        "outputId": "c72d7092-2eba-476e-8684-41e668ca116d"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "animalIdentifier(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_3): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Dropout(p=0.7, inplace=False)\n",
              "    (2): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze layers to preserve learned features from pretrained model\n",
        "\n",
        "for param in peopleClassifier.conv_block_1.parameters():\n",
        "  param.requires_grad = False\n",
        "for param in peopleClassifier.conv_block_2.parameters():\n",
        "  param.requires_grad = False\n",
        "for param in peopleClassifier.conv_block_3.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "for param in peopleClassifier.classifier.parameters():\n",
        "  param.requires_grad = True"
      ],
      "metadata": {
        "id": "yo2tscO7JK28"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Time to train\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "NUM_EPOCHS = 125\n",
        "\n",
        "# Reinitialize loss funciton & optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=peopleClassifier.parameters(),\n",
        "                             lr=0.0001,\n",
        "                             weight_decay=1e-5)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "# Timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  newTrainLoss, newTrainAcc = train_step(peopleClassifier,\n",
        "                                         new_train_loader,\n",
        "                                         loss_fn,\n",
        "                                         optimizer,\n",
        "                                         device)\n",
        "\n",
        "  print(f\"Epoch: {epoch} | Train loss: {newTrainLoss:.4f} | Train acc: {newTrainAcc:.4f}\")\n",
        "\n",
        "  # Unfreeze each block every 25 epochs for further adaptation to dataset, thus decreasing loss\n",
        "  if epoch == 41:\n",
        "    for param in peopleClassifier.conv_block_3.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    # Reinitialize optimizer to include newly unfrozen parameters\n",
        "    optimizer = torch.optim.Adam(params=peopleClassifier.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "\n",
        "  if epoch == 82:\n",
        "    for param in peopleClassifier.conv_block_2.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    # Reinitialize optimizer to include newly unfrozen parameters\n",
        "    optimizer = torch.optim.Adam(params=peopleClassifier.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "\n",
        "    # Once second conv block is unfrozen, step the scheduler after each epoch based on the training loss\n",
        "    scheduler.step(newTrainLoss)\n",
        "\n",
        "# End the timer\n",
        "end_time = timer()\n",
        "print(f\"Total training time: {end_time - start_time:.3f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-gGGySvHJCT",
        "outputId": "ad406047-e55a-4cc1-ea08-7a9c02e94072"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train loss: 2.4486 | Train acc: 0.1250\n",
            "Epoch: 1 | Train loss: 2.2674 | Train acc: 0.2273\n",
            "Epoch: 2 | Train loss: 2.0986 | Train acc: 0.2614\n",
            "Epoch: 3 | Train loss: 1.9372 | Train acc: 0.2614\n",
            "Epoch: 4 | Train loss: 1.9074 | Train acc: 0.3636\n",
            "Epoch: 5 | Train loss: 1.7583 | Train acc: 0.3636\n",
            "Epoch: 6 | Train loss: 1.6735 | Train acc: 0.4205\n",
            "Epoch: 7 | Train loss: 1.7110 | Train acc: 0.3636\n",
            "Epoch: 8 | Train loss: 1.8043 | Train acc: 0.3977\n",
            "Epoch: 9 | Train loss: 1.6771 | Train acc: 0.3750\n",
            "Epoch: 10 | Train loss: 1.5405 | Train acc: 0.4205\n",
            "Epoch: 11 | Train loss: 1.5666 | Train acc: 0.4432\n",
            "Epoch: 12 | Train loss: 1.6245 | Train acc: 0.4091\n",
            "Epoch: 13 | Train loss: 1.5382 | Train acc: 0.4545\n",
            "Epoch: 14 | Train loss: 1.4322 | Train acc: 0.5114\n",
            "Epoch: 15 | Train loss: 1.4365 | Train acc: 0.4659\n",
            "Epoch: 16 | Train loss: 1.4044 | Train acc: 0.5114\n",
            "Epoch: 17 | Train loss: 1.3429 | Train acc: 0.5341\n",
            "Epoch: 18 | Train loss: 1.3188 | Train acc: 0.5568\n",
            "Epoch: 19 | Train loss: 1.4736 | Train acc: 0.4432\n",
            "Epoch: 20 | Train loss: 1.3295 | Train acc: 0.5682\n",
            "Epoch: 21 | Train loss: 1.2509 | Train acc: 0.5455\n",
            "Epoch: 22 | Train loss: 1.3534 | Train acc: 0.6250\n",
            "Epoch: 23 | Train loss: 1.3030 | Train acc: 0.5909\n",
            "Epoch: 24 | Train loss: 1.2741 | Train acc: 0.5795\n",
            "Epoch: 25 | Train loss: 1.2621 | Train acc: 0.5000\n",
            "Epoch: 26 | Train loss: 1.1812 | Train acc: 0.5682\n",
            "Epoch: 27 | Train loss: 1.4213 | Train acc: 0.5455\n",
            "Epoch: 28 | Train loss: 1.2981 | Train acc: 0.5795\n",
            "Epoch: 29 | Train loss: 1.1508 | Train acc: 0.5795\n",
            "Epoch: 30 | Train loss: 1.2121 | Train acc: 0.5909\n",
            "Epoch: 31 | Train loss: 1.2816 | Train acc: 0.5568\n",
            "Epoch: 32 | Train loss: 1.1753 | Train acc: 0.6136\n",
            "Epoch: 33 | Train loss: 1.2290 | Train acc: 0.5568\n",
            "Epoch: 34 | Train loss: 1.2324 | Train acc: 0.6364\n",
            "Epoch: 35 | Train loss: 1.0590 | Train acc: 0.6705\n",
            "Epoch: 36 | Train loss: 1.2315 | Train acc: 0.5909\n",
            "Epoch: 37 | Train loss: 1.1246 | Train acc: 0.6023\n",
            "Epoch: 38 | Train loss: 1.1353 | Train acc: 0.6364\n",
            "Epoch: 39 | Train loss: 1.1872 | Train acc: 0.6250\n",
            "Epoch: 40 | Train loss: 1.1970 | Train acc: 0.5341\n",
            "Epoch: 41 | Train loss: 1.2516 | Train acc: 0.5568\n",
            "Epoch: 42 | Train loss: 1.1800 | Train acc: 0.6250\n",
            "Epoch: 43 | Train loss: 1.0422 | Train acc: 0.6591\n",
            "Epoch: 44 | Train loss: 1.1943 | Train acc: 0.5455\n",
            "Epoch: 45 | Train loss: 1.0697 | Train acc: 0.6477\n",
            "Epoch: 46 | Train loss: 1.0798 | Train acc: 0.6364\n",
            "Epoch: 47 | Train loss: 1.2449 | Train acc: 0.5455\n",
            "Epoch: 48 | Train loss: 1.1893 | Train acc: 0.5568\n",
            "Epoch: 49 | Train loss: 1.0961 | Train acc: 0.6136\n",
            "Epoch: 50 | Train loss: 1.0196 | Train acc: 0.6705\n",
            "Epoch: 51 | Train loss: 0.8774 | Train acc: 0.7273\n",
            "Epoch: 52 | Train loss: 0.9548 | Train acc: 0.6818\n",
            "Epoch: 53 | Train loss: 1.3274 | Train acc: 0.5795\n",
            "Epoch: 54 | Train loss: 1.2937 | Train acc: 0.5795\n",
            "Epoch: 55 | Train loss: 1.1742 | Train acc: 0.6250\n",
            "Epoch: 56 | Train loss: 0.9201 | Train acc: 0.6932\n",
            "Epoch: 57 | Train loss: 1.0426 | Train acc: 0.6591\n",
            "Epoch: 58 | Train loss: 1.3154 | Train acc: 0.5227\n",
            "Epoch: 59 | Train loss: 1.1152 | Train acc: 0.6477\n",
            "Epoch: 60 | Train loss: 0.9774 | Train acc: 0.5909\n",
            "Epoch: 61 | Train loss: 0.9877 | Train acc: 0.6705\n",
            "Epoch: 62 | Train loss: 1.0528 | Train acc: 0.6364\n",
            "Epoch: 63 | Train loss: 1.0614 | Train acc: 0.6818\n",
            "Epoch: 64 | Train loss: 1.0690 | Train acc: 0.6023\n",
            "Epoch: 65 | Train loss: 1.0170 | Train acc: 0.6250\n",
            "Epoch: 66 | Train loss: 1.0813 | Train acc: 0.6477\n",
            "Epoch: 67 | Train loss: 1.0717 | Train acc: 0.6136\n",
            "Epoch: 68 | Train loss: 0.9900 | Train acc: 0.6477\n",
            "Epoch: 69 | Train loss: 0.9495 | Train acc: 0.7045\n",
            "Epoch: 70 | Train loss: 0.8888 | Train acc: 0.6705\n",
            "Epoch: 71 | Train loss: 1.1822 | Train acc: 0.6818\n",
            "Epoch: 72 | Train loss: 0.9905 | Train acc: 0.5682\n",
            "Epoch: 73 | Train loss: 0.9275 | Train acc: 0.6705\n",
            "Epoch: 74 | Train loss: 1.0311 | Train acc: 0.6477\n",
            "Epoch: 75 | Train loss: 0.9924 | Train acc: 0.6477\n",
            "Epoch: 76 | Train loss: 1.0064 | Train acc: 0.6818\n",
            "Epoch: 77 | Train loss: 0.9998 | Train acc: 0.6477\n",
            "Epoch: 78 | Train loss: 1.0612 | Train acc: 0.6932\n",
            "Epoch: 79 | Train loss: 1.0377 | Train acc: 0.6705\n",
            "Epoch: 80 | Train loss: 0.9150 | Train acc: 0.6932\n",
            "Epoch: 81 | Train loss: 1.1867 | Train acc: 0.6023\n",
            "Epoch: 82 | Train loss: 0.9877 | Train acc: 0.6364\n",
            "Epoch: 83 | Train loss: 0.8800 | Train acc: 0.7045\n",
            "Epoch: 84 | Train loss: 1.0364 | Train acc: 0.6705\n",
            "Epoch: 85 | Train loss: 1.1626 | Train acc: 0.6250\n",
            "Epoch: 86 | Train loss: 0.9210 | Train acc: 0.6818\n",
            "Epoch: 87 | Train loss: 1.1564 | Train acc: 0.5455\n",
            "Epoch: 88 | Train loss: 0.9460 | Train acc: 0.7273\n",
            "Epoch: 89 | Train loss: 1.1156 | Train acc: 0.5795\n",
            "Epoch: 90 | Train loss: 1.1573 | Train acc: 0.5795\n",
            "Epoch: 91 | Train loss: 0.9853 | Train acc: 0.5909\n",
            "Epoch: 92 | Train loss: 0.9317 | Train acc: 0.7386\n",
            "Epoch: 93 | Train loss: 1.1085 | Train acc: 0.6364\n",
            "Epoch: 94 | Train loss: 0.8745 | Train acc: 0.6477\n",
            "Epoch: 95 | Train loss: 0.9497 | Train acc: 0.6705\n",
            "Epoch: 96 | Train loss: 1.1265 | Train acc: 0.6250\n",
            "Epoch: 97 | Train loss: 1.0089 | Train acc: 0.6818\n",
            "Epoch: 98 | Train loss: 1.0831 | Train acc: 0.6477\n",
            "Epoch: 99 | Train loss: 0.8435 | Train acc: 0.7614\n",
            "Epoch: 100 | Train loss: 0.8723 | Train acc: 0.7273\n",
            "Epoch: 101 | Train loss: 0.9362 | Train acc: 0.6591\n",
            "Epoch: 102 | Train loss: 0.9270 | Train acc: 0.6591\n",
            "Epoch: 103 | Train loss: 1.0391 | Train acc: 0.6477\n",
            "Epoch: 104 | Train loss: 1.0513 | Train acc: 0.5795\n",
            "Epoch: 105 | Train loss: 0.9598 | Train acc: 0.6250\n",
            "Epoch: 106 | Train loss: 0.9289 | Train acc: 0.6591\n",
            "Epoch: 107 | Train loss: 0.6823 | Train acc: 0.7727\n",
            "Epoch: 108 | Train loss: 1.0921 | Train acc: 0.6250\n",
            "Epoch: 109 | Train loss: 1.1078 | Train acc: 0.6364\n",
            "Epoch: 110 | Train loss: 1.1488 | Train acc: 0.6364\n",
            "Epoch: 111 | Train loss: 1.0286 | Train acc: 0.6477\n",
            "Epoch: 112 | Train loss: 0.9163 | Train acc: 0.7386\n",
            "Epoch: 113 | Train loss: 0.8998 | Train acc: 0.7045\n",
            "Epoch: 114 | Train loss: 1.0896 | Train acc: 0.6818\n",
            "Epoch: 115 | Train loss: 1.1489 | Train acc: 0.5795\n",
            "Epoch: 116 | Train loss: 0.8974 | Train acc: 0.6477\n",
            "Epoch: 117 | Train loss: 0.8755 | Train acc: 0.7273\n",
            "Epoch: 118 | Train loss: 0.8957 | Train acc: 0.6705\n",
            "Epoch: 119 | Train loss: 0.9060 | Train acc: 0.6932\n",
            "Epoch: 120 | Train loss: 1.0995 | Train acc: 0.6591\n",
            "Epoch: 121 | Train loss: 1.1475 | Train acc: 0.6250\n",
            "Epoch: 122 | Train loss: 0.7990 | Train acc: 0.7386\n",
            "Epoch: 123 | Train loss: 1.1157 | Train acc: 0.6705\n",
            "Epoch: 124 | Train loss: 1.3115 | Train acc: 0.6136\n",
            "Total training time: 362.473 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model directory\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True,\n",
        "                 exist_ok=True)\n",
        "\n",
        "# Create model name & save path\n",
        "MODEL_NAME = \"peopleClassifier.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# Save model's weights to created path\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=animalModelV2.state_dict(),\n",
        "           f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMN4LI_AJQfg",
        "outputId": "8d1b0db2-d818-4c81-f724-2070a2ec54ad"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to: models/peopleClassifier.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UmRvGvtbnoie"
      },
      "execution_count": 223,
      "outputs": []
    }
  ]
}